% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/utils.r
\name{llama_size}
\alias{llama_size}
\title{Estimate LLaMA Total Parameters}
\usage{
llama_size(vocab_size, n_layer, n_head, n_embed, multiple_of = 256L)
}
\arguments{
\item{vocab_size}{number of vocabulary tokens}

\item{n_layer}{number of transformer layers}

\item{n_head}{number of transfomer heads per layer}

\item{n_embed}{size of feature (embedding) dimension}

\item{multiple_of}{number to round feedfoward dimension to}
}
\description{
Estimate LLaMA Total Parameters
}
\examples{
llama_size(32000, 32, 32, 4096, 256) # llama-7B
llama_size(32000, 40, 40, 5120, 256) # llama-13B
llama_size(32000, 60, 52, 6656, 256) # llama-32.5B
llama_size(32000, 80, 64, 8192, 256) # llama-65.2B
}
